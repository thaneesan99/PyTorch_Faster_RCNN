{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaneesan99/PyTorch_Faster_RCNN/blob/main/Train_PyTorch_Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xipBWy7kC5gQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from torchvision.ops import box_iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqVNW43QD9A_"
      },
      "outputs": [],
      "source": [
        "# Download the file from the specified URL\n",
        "!wget \"place_your_dataset_link\" -O dataset.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip dataset.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4Xh7kgaEDcG"
      },
      "outputs": [],
      "source": [
        "# Load CSV and prepare datasets\n",
        "train = pd.read_csv('/content/train/_annotations.csv')\n",
        "valid = pd.read_csv('/content/valid/_annotations.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTpgTOYfEL69"
      },
      "outputs": [],
      "source": [
        "train_unique_imgs = train.filename.unique()\n",
        "valid_unique_imgs = valid.filename.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j--V0Qk-EjRV"
      },
      "outputs": [],
      "source": [
        "class CustDat(Dataset):\n",
        "    def __init__(self, df, unique_imgs, root_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.unique_imgs = unique_imgs\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.unique_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.unique_imgs[idx]\n",
        "        # Filter bounding boxes for the current image\n",
        "        boxes_df = self.df[self.df.filename == image_name][['xmin', 'ymin', 'xmax', 'ymax']]\n",
        "        boxes = boxes_df.values.astype(\"float\")  # Convert bounding box coordinates to float\n",
        "        img_path = os.path.join(self.root_dir, image_name)\n",
        "        img = Image.open(img_path).convert('RGB')  # Open the image\n",
        "\n",
        "        # Assuming a single class for all boxes (can be adjusted as needed)\n",
        "        labels = torch.ones((boxes.shape[0]), dtype=torch.int64)\n",
        "\n",
        "        # Prepare the target dictionary\n",
        "        target = {\n",
        "            'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "        # Apply any transformations to the image\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQEgW0KfFRSu"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_dataset = CustDat(df=train, unique_imgs=train_unique_imgs, root_dir='/content/train',\n",
        "                        transform=T.ToTensor())\n",
        "valid_dataset = CustDat(df=valid, unique_imgs=valid_unique_imgs, root_dir='/content/valid',\n",
        "                        transform=T.ToTensor())\n",
        "\n",
        "# Create dataloaders\n",
        "train_dl = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_AJIx_oGHs0"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "310_yZOUGas1"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "num_classes = 2\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKew5r_sGtUN"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NosAqqEJx7e"
      },
      "outputs": [],
      "source": [
        "save_dir = \"faster_rcnn_model\"\n",
        "os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8N7SQogMyaN"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # TRAINING\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for imgs, targets in train_dl:\n",
        "        imgs = [img.to(device) for img in imgs]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Forward pass\n",
        "        loss_dict = model(imgs, targets)\n",
        "        loss = sum(v for v in loss_dict.values())\n",
        "\n",
        "        # Accumulate epoch loss\n",
        "        epoch_loss += loss.cpu().detach().numpy()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Save model every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        save_path = os.path.join(save_dir, f\"faster_rcnn_epoch_{epoch + 1}.pth\")\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model saved at {save_path}\")\n",
        "\n",
        "    # VALIDATION\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in valid_dl:\n",
        "            imgs = [img.to(device) for img in imgs]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            outputs = model(imgs)  # Predictions from the model\n",
        "\n",
        "            # Validate predictions\n",
        "            for i, output in enumerate(outputs):\n",
        "                pred_boxes = output[\"boxes\"].cpu()\n",
        "                pred_labels = output[\"labels\"].cpu()\n",
        "                gt_boxes = targets[i][\"boxes\"].cpu()\n",
        "                gt_labels = targets[i][\"labels\"].cpu()\n",
        "\n",
        "                # IoU matching between ground truths and predictions\n",
        "                if len(gt_boxes) > 0 and len(pred_boxes) > 0:\n",
        "                    iou_matrix = box_iou(gt_boxes, pred_boxes)\n",
        "\n",
        "                    for gt_idx, gt_label in enumerate(gt_labels):\n",
        "                        max_iou, pred_idx = iou_matrix[gt_idx].max(0)  # Best match for each GT box\n",
        "                        if max_iou > 0.9:\n",
        "                            y_true.append(gt_label.item())\n",
        "                            y_pred.append(pred_labels[pred_idx].item())\n",
        "                        else:\n",
        "                            # False negative for unmatched ground truths\n",
        "                            y_true.append(gt_label.item())\n",
        "                            y_pred.append(0)  # Assume unmatched predictions as class 0\n",
        "\n",
        "                    # False positives for unmatched predictions\n",
        "                    matched_pred_indices = iou_matrix.argmax(0)\n",
        "                    unmatched_preds = set(range(len(pred_boxes))) - set(matched_pred_indices.tolist())\n",
        "                    for pred_idx in unmatched_preds:\n",
        "                        y_true.append(0)  # No ground truth\n",
        "                        y_pred.append(pred_labels[pred_idx].item())\n",
        "                else:\n",
        "                    # If no predictions or no ground truths, handle accordingly\n",
        "                    y_true.extend(gt_labels.tolist())\n",
        "                    y_pred.extend([0] * len(gt_labels))  # All are unmatched (false negatives)\n",
        "\n",
        "                    y_true.extend([0] * len(pred_boxes))  # All predictions are unmatched (false positives)\n",
        "                    y_pred.extend(pred_labels.tolist())\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
        "\n",
        "\n",
        "    # Print validation metrics\n",
        "    print(f\"Validation - Epoch [{epoch + 1}/{num_epochs}]:\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0WlQiRQONvW"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/faster_rcnn_model/faster_rcnn_epoch_100.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}